---
layout: post
title: 基于SIMD指令集的SM4优化实现
categories: Network
keywords: TLS, GM, Network
---

## 背景       
当前国密算法目前存在一个痛点就是速度不够快，今天我们这篇文章聚焦国密算法中的对称加密算法—SM4算法，分析一下SM4算法为什么慢，并探讨下其相应的优化方案。这篇文章将对并行化技术，SM4算法的原理及如何进行优化做一个简要的分析，内容简介如下：
- 第二章: 优化结果，如果你只对优化结果和如何使用感兴趣，那么只用看第二章和第六章就好了。
- 第三章:SM4算法分析，本章会对SM4的加密流程做一个详细的说明，如果你好奇SM4加密算法的流程，可以仔细看看本章。
- 第四章:SIMD指令集概述，本章会简要分析SIMD指令集的加速原理并分享简单的使用样例，如果你对并行加速感兴趣，可以看一看这一章。
- 第五章: SM4算法的优化加速，本章依赖第三章和第四章的一些知识，对于我们如何进行SM4性能优化做了分析。
- 第六章: 简介了一下我们的[BabaSSL开源库](https://github.com/BabaSSL/BabaSSL)，如果你对于密码库有任何需求或建议，或者期望使用到各种经过优化的国密算法，请联系我们。


## SM4优化性能对比
并行加速依赖于算法本身能够抽象出很多独立的单元，于SM4而言，符合这个特质的只有ECB，CTR，GCM这几种模式，根据使用的普适性，我们对于SM4-ECB及SM4-GCM模式进行了优化，下面是我们优化前后的性能对比：

SM4-ECB算法性能对比：
|  type   | 速度  |
|  ----  | ----  |
| SM4-ECB(未做优化)  | 79.998MB/s |
| SM4-ECB(SIMD指令集优化)  | 206.565MB/s |

SM4-GCM模式中性能对比：
|  type\明文block_size   | 16bytes  | 64bytes  | 256bytes  | 1024bytes  |
|  ----  |  ----  |  ----  |  ----  |  ----  |
| SM4-GCM(未做优化)  | 89.914MB/s | 105.520MB/s | 109.293MB/s | 110.836MB/s |
| SM4-GCM(SIMD指令集优化)  | 91.868MB/s | 189.361MB/s | 203.685MB/s | 204.498MB/s |

可以看到，对于SM4-ECB而言，基于SIMD指令集优化可以将速度提升至原来的2.6倍，而对于GCM模式下的SM4算法，基于SIMD指令集可以将性能优化至接近原来的2倍。在讲解我们如何做优化之前。我们先来看下SM4算法的流程。

## SM4算法流程简介
我们首先多花点篇幅熟悉下SM4算法的基本流程，在了解了SM4的流程后，你不仅能了解到其性能低的原因，同时在后文分析其可以优化的点以及为何如此优化时也会更加清晰。首先我们先讲解一些基本概念并定义一些变量(可以先不用着重看这部分，在后文看到相应的运算有不懂再过来查即可):

- SM4是一种128bit的分组密码算法，所谓分组，就是明文将会按128bit分成一个个小组进行加密。
- SM4有两个输入：明文(128bit)，定义为X；对称密钥(128bit)，定义为K。一个输出：密文(128bit)，定义为Y。明文我们将按32bit分别定义为4个变量，即X = {X0, X1, X2, X3}，同样，我们也定义Y = {Y0, Y1, Y2, Y3}。
- 定义一个S盒以及查表运算S(x)，x要求为8bit正整数，S(x)就是去查S盒里索引为x的数据
- 定义一个非线性运算τ(x)，x要求为32bit正整数，τ(x) = (S(x >> 24 & 0xff) << 24)⊕(S(x >> 16& 0xff) << 16)⊕(S(x >> 8 & 0xff) << 8)⊕S(x & 0xff)，这个运算看似复杂，实际上很简单，就是将32bit的x分为4个8bit数，然后分别到S盒内查表，然后再拼接起来就行了。
- 定义一个线性运算L(x)，L(x) = x⊕(x<<2)⊕(x<<10)⊕(x<<18)⊕(x<<24)，L(x)的作用是加密扩散，即即使明文只改动一点，密文也会发生很大的变化。
- 定义核心变换运算T(x)，T(x) =τ(L(x))，即先进行L变换再进行τ变换。

SM4核心的数学运算就这些了，看似繁琐，实则十分简单，重要的是把握每一个步骤的目的。下面我们开始分析SM4的流程，SM4的核心流程分为两步：
- 密钥扩展，即将K通过密钥扩展算法导出成32个轮密钥，记做rki(0 <= i <= 31)，这一步可以做优化的部分较少，因此我们只简要说明流程，rk通过K作为基本的秘钥数据，再通过一些算法生成轮秘钥，在密钥拓展中，我们通过一些常数对K进行操作，增大随机性。目前SM4固定了系统参数FK以及固定参数CK。FK，CK和S盒类似，都是固定好的，理解成数组就行了，轮密钥导出方式如下：

![](/images/self-drawn/sm4-simd/sm4-algo.png)

- 轮函数加密，轮函数加密也是一个相当简单的东西，在这里还需要定义一个轮函数F：
```
F(X0, X1, X2, X3, rk) =X0⊕T(X1⊕X2⊕ X3⊕ rk)
```
至于为什么叫轮函数，看完加密过程的图就清楚了

![](/images/self-drawn/sm4-simd/sm4-round.png)

至此，对于了解AES的同学，SM4性能低的原因就呼之欲出了，如果你不了解AES也没关系，这里总结一下([想具体了解AES的同学请看这里](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard?spm=ata.21736010.0.0.60397cadFsT22U))：
- 相比AES，SM4需要经过32轮加密，而AES只需要10轮加密。
- 相比AES来说，SM4的轮函数更加复杂。
- AES由于其通用性，各类厂商的CPU都有其专门的硬件加速指令，而SM4目前只有纯软件实现。
SM4作为一种对称加密算法，很多特性和AES是类似的，AES采用了SIMD指令集来进行加速，所以直观的我们也想到了能不能使用SIMD来加速SM4。下面我们对SIMD指令做一个简要说明。

## SIMD指令集概述
SIMD指令集并不是一个很新的东西，从最早只支持64bit寄存器的MMX到后来支持128bit寄存器的SSE，SSE2-4，再到近些年支持256bit，512bit的AVX，AVX2，AVX512，其本质上的演进都是在不断扩大寄存器的位宽，同时提供更加丰富的指令集。那么何为SIMD呢？我们忽略掉硬件实现上的交织，流水等技术，仅从应用层面来理解SIMD的功能，SIMD全称为"Single Instruction Multidata"，意为单指令多数据，听起来还是有些茫然，我们先来看一个例子：
```
for (i = 0; i < 3; i++) {
    arr[i]++;
}
```
对于这一段代码来说，每一个循环都会执行一次加法指令，我们可以称这个过程为单指令单数据，即一条加法指令只操作了一个寄存器。可以看到，cpu需要至少执行4个加法指令才可以实现这个过程，而如果我们将实现变成这样：

![](/images/self-drawn/sm4-simd/simd.png)

我们的cpu能不能通过一条指令完成这四个寄存器同时相加呢？答案是肯定的，这就是单指令多数据的意义所在，通过数据的合理放置，以减少cpu的指令消耗SIMD实质上是通过一个大位宽的寄存器实现的上述图中的4个小寄存器，更具体的细节这里就不赘述了。在这种思路下写出来的代码长这样：
```
//小端机器的写法，实质上就是4个0x1,aligned(0x10)表示按16字节对齐
const __m128i ctr __attribute__((aligned(0x10))) =
        { 0x0100000001000000, 0x0100000001000000 };
const __m128i arr_simd __attribute__((aligned(0x10)));

arr_simd = _mm_set_epi32(arr[3], arr[ 2], arr[ 1], arr[ 0]);
arr_simd = _mm_add_epi32(arr_simd,ctr);

//再将arr_simd的数据分别读取到arr中即可
```

从整体来看，代码似乎变得复杂，也多了很多内存拷贝的开销，但请注意，如果我们不是单单执行简单的加法，而是各种耗时巨大的计算任务，那SIMD指令将会带给我们巨大的收益。也就是说，如果你的计算任务中可以抽象出很多可以同时计算的部分，那么不妨尝试下使用SIMD技术来进行加速，并且SIMD的能力远不止我提到的这么简单，针对某些特定指令集还有一些特定的硬件处理优化，其带来的性能提升可能会超乎你的想象。

当然SIMD使用限制条件也就很明显了，就是要求你的计算流程能够抽象出部分能够并行且独立计算的流程，如果我们的目标是实现下面这个功能，SIMD指令集就爱莫能助了。
```
for (i = 2; i < 4; i++) {
    arr[i] = arr[i-1] + arr[i-2];
}
```

在[intel的SIMD指令集官网](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)上可以查到各式各样的指令集和其对应的功能详解，你可以通过如下命令来查看你的机器对于各种系列的SIMD指令集的支持：
```
gcc -march=native -dM -E - < /dev/null | grep -i "sse\|avx"
```

## SM4算法优化
根据第四章对于SIMD指令集的介绍，我们了解到若要使用SIMD来优化到SM4的流程上，必须要其计算过程能够抽象出很多并行计算的流程来。回顾第三章对于SM4算法的介绍，SM4核心的计算流程在于32轮的轮函数的调用，然而每一轮轮函数的输入都依赖上一轮的输出，从这个流程上来看，SM4算法内部似乎没有通过SIMD优化的可能性，只能转向对称加密的应用层面寻求抽象，在实际应用中，对称加密的应用模式很多，典型如ECB，CTR，OCB，GCM，CCM等，由于篇幅的原因，我们这里就只介绍实际应用中大量使用且存在可优化点的ECB模式和GCM模式，我们来看看这两种模式：
- ECB模式是最基本的加密模式，本质上就是分组然后加密然后再组合起来。这种模式由于安全性问题，在实际应用中并不推荐使用，但作为一个最基本的加密模式，用来作为性能参照和学习是最好不过的，其流程如下图：

![](/images/self-drawn/sm4-simd/ecb-enc.png)

- GCM，GCM是目前使用最多的模式，不仅提供了消息的加密能力，同时也提供了消息的认证能力，TLS1.3明确要求record层需要使用GCM或者CCM模式。[关于GCM模式的详细说明看这里](https://en.wikipedia.org/wiki/Galois/Counter_Mode?spm=ata.21736010.0.0.60397cadFsT22U)，这里只给个简要的说明图：

![](/images/self-drawn/sm4-simd/gcm-enc.png)

可以看到，我们找到了可以抽象出来的并行计算过程，剩下的就是繁琐的代码编写工作了，一些细节的优化这里就不赘述了，通过SIMD指令集，这两种加密模式的性能得到了巨大的提升，具体数据请看第二章给出的性能说明。

这里再分享一个优化点，虽然SM4内部无法通过SIMD优化，但并不代表它没有优化的可能，我们来看一下轮函数加密过程的T(x)变换过程，T(x)中的τ(x)本身就是一个查表运算，而L(x)变换是一个线性变化，得益于二元域上线性变换的性质，我们可以推导出：T(x) =τ(L(x)) = L(τ(x))，为了简化整个优化流程的推导，我们记32bit输入X = {X0, X1, X2, X3}('{}'表示将几个8bit值按位组合起来)，推导过程如下：
```
T(x) = L((S(x0) << 24) ⊕ (S(x1) << 16) ⊕ (S(x2) << 8) ⊕ S(x3))
     = L(S(x0) << 24) ⊕ L(S(x1) << 16) ⊕ L(S(x2) << 8) ⊕ L(S(x3))
     = (L(S(x0)) << 24) ⊕ (L(S(x1)) << 16) ⊕ (L(S(x2)) << 8) ⊕ L(S(x3))
```

注意几个括号的位置，可以看到，整个T(x)的变换过程可以等价为一个S盒经过L变换得到的Sbox_T，从而优化掉L(x)的计算过程。

## 结语
至此，SM4的核心优化思路就基本讲完了，应该来说优化的大体思路是相当简单的，相对繁琐的是编码工作，而这一部分我们已经完成，并在我们的[BabaSSL开源库](https://github.com/BabaSSL/BabaSSL)上线，对这块细节感兴趣的同学可以通过源码来看一下其中的一些技巧。