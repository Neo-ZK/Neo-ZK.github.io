---
layout: post
title: 深入HTTP/3(2)---站在H3看H4
categories: Network
keywords: HTTP/3, QUIC
---

## 写在前面
在上一篇文章中，我们通过对HTTP/3的设计分析，总结了从HTTP/1到HTTP/3这一路以来，应用层协议和传输层协议融合的趋势，那么我们今天不妨更大胆一点，以之前的协议发展史为鉴，构想一下下一代协议HTTP/4的样子。网络毫无疑问是当前时代的一个重要基础设施，同为基建，我们很少能听见诸如“下一代地铁”，“下一代公路”这样的词汇，然而我们似乎在建设下一代网络的路上从来没有停过，5G还没落地，我们就开始了6G的研究，我们在不断充实我们的有线通信和无线通信技术的同时，我们也没耽搁量子通信这一类跨时代技术的研究。本质上来说，当“下一代”被反复提及时，意味着需求和技术发展产生了一个良好的循环，技术不断在催生新的业务，而新的业务又在向技术提出更高的诉求。网络协议作为网络的核心部分，理所应当也需要不断往下一代发展，下一代意味着对当前问题的解决，也意味着对新的诉求的契合，我们可以借着对下一代协议的展望来好好梳理下当前网络到底存在着什么样的问题，以及在协议层面到底面临着哪些诉求。

当然，本文的诞生也存在某种程度上的心路历程，在写这篇文章之前，本人就协议发展史和下一代协议这个话题做过一次线上分享。然而不幸的是，一位路人同学在听完分享后提了一个问题，“为什么感觉网络协议就是一个骗局，而运营商就是跟着恰烂钱的拦路虎？”这个问题的出现让我颇具挫败感，诚然，搞技术分享有点像吵架，总觉得下次还可以搞的更好，而回头来看，上一次的分享不那么成功的原因可能是分享的思路偏向自底向上的技术探索视角，那么这一次，我们不妨用以自顶向下的需求视角来好好推导一下，下一代协议，或者说HTTP/4到底会是什么样子。

## 如何定义下一代
什么样的协议可以称作下一代呢？如果单纯只是定义一些技术提升指标并将其实现，那么我觉得这远不能达到我们对下一代的诉求，比如如果我对协议某些细节做了微调再配合一些硬件设备的迭代，我可能将协议栈的吞吐量翻了一倍，但这肯定不能算是下一代。下一代应当是对当前需求及痛点问题的集中整理，并从源头上给出的解决方案，我们不妨从TCP/IP和HTTP协议的发展史来看，每一次大版本的升级往往不外乎以下原由：

1. 上层的需求发生了变化，当前的协议满足不了，比如IP，TCP等协议的诞生
2. 本身协议的设计在上一代存在太多漏洞，现在用起来太多问题，比如从SSLV2.0到TLS1.3
3. 底层传输协议发生了革新，上层协议需要做一些调整适配，比如TCP和HTTP /3的诞生。

按照这个思路来看，如果我们将HTTP/3作为第一视角，那么交互层面已经实现了0-RTT功能，功能层面我们也实现了精准的文件操作语义以及数据的原生安全能力，已经没有太多的痛点问题存在了，这一层发生革新的可能性看起来不大，那么从上层需求和底层来看，还有进化的可以能吗？我们来逐一梳理下。

## 需求的变迁
虽然应用层协议才是真正面向业务需求的协议，但由于整个技术趋势逐渐开始往传输层和应用层不分家的方向发展，那我们这里也就合在一起讨论，整个传输层/应用层层协议几乎一直以来都是一个需求驱动的技术，从功能层面上来说，需求主要分成两个类型：

1. 向上的贴合业务层面的诉求
2. 向下提供对底层网络的精细控制能力

对贴合业务这个点来说，典型的例子如流媒体这种业务，需要精准的预测带宽，以适配视频码率；也如大家最熟知的各种文件传输业务，需要的就是精准的文件操作语义。随着业务场景越来越复杂。如果每一种业务场景都需要一套单独的协议去适配，那么对于开发人员来说无论是使用成本还是学习成本都实在是太高了。这也就意味着需要一种尽可能涵盖更多业务场景的协议，当然这是一种比较理想的思路，这就像中台建设一样，未来到底有什么业务是确实无法预期的，而新的业务往往又和已有的技术有着某种程度的冲突，这样就会导致一种老技术反而阻碍了新的技术发展这一奇怪的现象。从这个角度来说，我们可能需要的是一种涵盖各种协议的的框架，而不是一种协议支持各种各样的功能，因为协议本身标准化的流程特别长，如果还涉及到内核部分的修改，那么等OS的更新就会成为另一个令人头疼的问题。顺着这个思路来看，webtransport这种在浏览器端去把多协议框架支棱起来的技术，已经走在了正确的道路上，不过我这里也想提一点，随着QUIC这样的用户态协议开始普及，并且IETF组织对于广大开发人员也越来越友好，那么其实在某种意义上，我们在QUIC层面去做这种多协议框架也是一种不错的思路，而实际上，某些FEC+QUIC做特殊场景传输之类的技术也已经开始在标准化的道路上了，这个未来是值得期待的。

而对于掌控底层网络这部分需求来说，一个典型需求方就是云厂商，随着云变成新一代基础设施，云厂商们为了在网络层面提供确切的SLO和SLA，自然而然的也就会想办法在更底层的网络设备上具备更强的掌控力，以到达网络设备全链路metrics，传输稳定甚至传输时延可控的效果。然而现代网络协议栈的设计思路是分层协作，不同层级间提供统一的使用统一的接口以达到工程效能的最大化，我们虽然不能肯定的说这个愿景完美的实现了，但至少从产业链上形成了某种解耦，而解耦往往意味着墙的出现。云厂商想了解一次请求过程中，底层网络各个设备具体的行为和设备的状态在现有的模式下几乎不可能。当然，这可能也需要归咎于IP协议本身的设计，IP协议期望解决的问题是如何屏蔽底层异构设备的特殊性，达到全网互联互通的效果，相对比较简单的问题也就对应了不复杂的解决方案，即通过一个统一的路由来为底层报文打上一层新的身份。这种瘦腰型的设计导致了本身IP协议面向上层协议的扩展就很少，这也就导致了上层协议很难针底层的行为做个性化的使用。虽然IP协议看起来也一直也没有停下进化的脚步，我们也很长一段时间都在持续从从IPV4迁移到IPV6，但IPV6毕竟是98年的技术，在当时也并未面临着上层如此复杂的网络情况，所以也难以完美契合现在的诉求。至此，我们不妨来看看IP层到底面临什么样的问题，又存在什么样的革新的可能。

## IP层的问题
前文也已经提到过了，IP协议诞生的目的是解决底层网络异构互通的问题，而其解决的手段就是为所有底层的传输报文提供了一个统一的“身份”，而在当年的网络背景下，这个统一的“身份”的仅仅只是解决了路由的问题，而并没有解决身份的可信问题，这也就导致现在的很多基于IP地址DDOS防护都是理论上不可靠的，因为任何攻击者都有伪造地址的可能。受此影响，上层也不得去做一些安全机制来应对相应的问题，比如QUIC就搞了一个address validation的验证机制来防范相关的放大攻击。在当前网络环境下，这一类的机制往往会是协议栈性能的瓶颈所在，举个例子，某些NAT设备对UDP的支持其实并不是很友好，UDP报文在NAT设备中的映射关系持续时间很短短，这会导致一个现象，服务端经常会看到底层报文的IP地址发生变迁，因而触发address validation机制，而address validation机制既需要通信两端的交互，又要加解密算法的操作，这会对协议栈的吞吐量带来非常大的挑战。

除了如何构建可信的身份体系外，如何管理上层使用者的身份也是一个问题，从逻辑上而言，是先有了用户，才有了身份，就这个问题来看，如果想依赖现有的PKI技术构建可靠的路由体系，IP层断然是需要将TLS相关技术进行下沉的，而这势必会对现有协议的交互流程进行重构。当然，身份是一个话题，如何更好的契合上层业务又是另一个话题，不同业务之间对网络质量诉求是不一样的，而IP作为一个路由协议，直接决定了数据的路径，而数据的路径往往又决定了网络质量，这也就意味着，类似5G网络切片这一类的QOS技术如果要做到极致，是需要尽可能感知上层业务的行为的，而这也就需要IP层对链路的特性做足够的建模和抽象，并向上层提供统一易用的使用接口，现阶段的IP协议是显然做不到这一点的。

除了对上层提供的功能不够的问题之外，IP层自身也或多或少存在着功能薄弱的问题。而这样的现状是有历史原因的，TCP/IP协议栈成功的一大因素就是简化了中间节点的功能，中间节点只需要做尽力而为的转发，这样大大简化了中间节点的成本，使得大规模的网络得以在一个较低的成本下可以建设起来。然而网络发展到今天，中间设备性能已经有了很大的进化，我们是可以利用中间节点来做更多的事情的。我们前面提到，IP层面既然决定了路由，也就决定了一个报文的物理传输路径，而这其实也就引出了两个可以继续深入探讨的问题：

1. 如何通过更智能的路由实现更短的传输路径？
2. 如何在路由层面实现网络吞吐量的最大化？

这两个问题并不完全独立，比如我们可以通过某种手段去预探测到最短路径，以达到更短传输路径的物理时延，但如果所有报文都一起走这一条看起来最短的链路，那么往往这条路径就会发生拥塞，网络的吞吐量反而会大幅度下降。而这也就牵出了SDN和SDWAN这一类流量工程相关的技术，相关技术将IP协议作为承载相关路由信息的数据面技术，并在更中心化的控制面去感知全网拓扑以及链路的质量状况，以此为每个节点分配最合适的策略。而这里其实也和前面的诉求遥相呼应，如果要更精细化的调度流量，那么就需要对流量的模型有一定了解，也同样也意味着需要感知业务，至此我们其实已经粗略的感知到当前协议继续向下融合的趋势，简单小节一下：

![](/images/self-drawn/h3-2-h4/f1.png)

## 向下看
如果向下融合是一种趋势，我们不妨继续往下寻找问题和革新的可能。站在当前网络技术的视角上，IP层确实有很多问题，但就算IP层有99%的锅，底层难道就没有1%吗？实际上底层该背的锅也一点不小，我记得当年玩魔兽世界的时候，有个非常典型的问题，某些机器明明网络还可以，但还是会频繁丢包，而丢包的罪魁祸首就来自于2层的MTU，我觉得这个例子用来说明底层的问题再好不过，MTU是链路层最大传输单元的大小，当IP报文超过这个长度时，就会发生IP分帧，而分帧后两个报文如果没有都成功传递到对面，那么整个原始IP报文就视作丢包了，可以看到，发生分帧后，不仅传输的数据会变多(新增了一个IP报文头)，数据的传输失败率也是被乘数放大了，这对网络体验的影响非常之大，不仅如此，分帧行为对于中间路由设备也并不那么友好，大部分中间设备在频繁进行IP的分帧重组时，吞吐率会大大降低。

而这跟IP层协议有什么关系呢？首先当前一个通用的MTU的值是1500，这个值是一个在当年3Mb/s的网络环境下的最佳实践数据，在当前的网络状况下，已经十分偏小了，较小的MTU值就意味着上层的报文设计需要尽可能的精简报头，否则稍长一点的报文就会引起IP分帧，而无论是对使用者还是设计者来说，如果每一个新的场景，都需要抠抠搜搜的去报文头部里去谋求一点弹丸之地，那无疑是一场噩梦。再者，MTU是一个具有木桶效应的值，由整条链路上所有设备的最低MTU值来决定，比如刚刚提到的解决卡顿的方案就是调低游戏设备的MTU值，使其低于整个传输链路上所有设备的最低MTU值，这意味着升级MTU的过程绝对是一个漫长而且艰辛的过程，广大厂商除非有一些特别重要的理由，否则肯定是没有动力来做这个事情的。

## 直面最底层
其实从前面几节的分析，我们也逐渐发现了一些现代网络协议的问题，现代网络协议栈的设计思路是分层协作，但随着技术的演进，层级间却出现了一定程度的耦合，比如前文所述的升级依赖：

![](/images/self-drawn/h3-2-h4/f2.png)

当依赖形成后，任何一层想要进行单方面的升级都是困难的，那么最根源的问题是物理层吗？物理层表示这个锅它不背，还是以这个典型的MTU问题为例，其实底层无论是交换链路带宽还是锁相环的稳定性问题，早就已经得到了解决，甚至稍显黑色幽默的是，反而是物理层这些年做的足够好，底层带宽有符合摩尔定律式的发展，才让这些问题显得不那么突兀，也就一直得不到解决。

可惜的是，物理层的发展出现了摩尔定律失效的问题，虽然物理层有着理论上非常美好的明天：比如无线频谱资源是理论上无限的，如果我们的通信手段可以保证在任意频段下任意传输距离，都能够有足够好的传输效率，那么我们干嘛还需要这么繁琐的协议分层呢，直接人人分配一个频段就好了；或者再干脆一点，我们一步迈入量子通信时代，直接颠覆现有的传输技术，届时，新的身份和安全体系也会重新提出，完全不用考虑现有的历史包袱。

当然，这样的YY确实有点过于丰满了，虽然网络协议存在理论上非线性进化的可能性，但5G在某种程度上的折戟就足够给这些畅想当头一棒，何况现阶段的量子通信构想仍旧需要依赖现有的网络技术去同步一些信息，所以，在我们肉眼可见的未来，物理层应该很难有飞跃式的进步，同时物理层当下又没有明显的制约下一代协议发展的要素，所以协议演进的关键点还在2/3层。

## 眼中的下一代
目前似乎看起来顶层需求也非常明确，底层技术也有了足够的支撑，那么是什么制约了发展呢，总不能是二三层的设计技术能力不足吧？站在运营商的视角来看，其实问题还是很明确的，本身技术的迭代往往是一个成本和收益的问题，就如前文所说的那样，二三层有太多的历史包袱，升级换代本就不容易，就算有了技术方案，也需要做成大家都认可标准，并呼吁各大ISP都来支持，才有顺利演进的可能，少了其中任何一环都不行。而网络技术是一个信奉“it just work”信条的技术，既然现有的技术跑的也还行，又有SDWAN这些又能有兼容性，又能给未来几年带来一些收益的技术，那么我干嘛要升级呢？

所幸，营收不会骗人，单纯靠卖带宽就能躺着把钱挣了的时代已经一去不复返了，通货在膨胀，ISP厂商的营收却在下降，换谁都得着急。各大云厂商已经向ISP证明了，还是得面向服务才有好果子吃，所以ISP也开始发力搞云网融合了，要想从各大云厂商里面抢蛋糕，不拿出点真东西来是不行的，作为真正把网络闭环了的云网一体项目，也许才是新一代协议发展的最好温床，最后我们似乎就理清了这个思路：

![](/images/self-drawn/h3-2-h4/f3.png)

至于这个下一代协议，也许是叫QUIC-v2，也许是叫HTTP/4，又或者是别的什么名字，不过又有什么关系呢？